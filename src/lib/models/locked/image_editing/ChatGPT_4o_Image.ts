/**
 * üîí LOCKED MODEL: ChatGPT 4o Image
 *
 * Group: image_editing
 * Provider: kie_ai
 * Content Type: image
 *
 * ‚ö†Ô∏è DO NOT EDIT THIS FILE MANUALLY
 * This file is the single source of truth for this model
 */

import { getGenerationType } from "@/lib/models/registry";
import { supabase } from "@/integrations/supabase/client";
import type { ExecuteGenerationParams } from "@/lib/generation/executeGeneration";
import { reserveCredits } from "@/lib/models/creditDeduction";
import { GENERATION_STATUS } from "@/constants/generation-status";
import { sanitizeForStorage } from "@/lib/database/sanitization";

// MODEL CONFIGURATION
export const MODEL_CONFIG = {
  modelId: "4o-image-api",
  recordId: "4b68811b-28be-45cb-bcae-9db721ba4547",
  modelName: "ChatGPT 4o Image",
  provider: "kie_ai",
  contentType: "image_editing",
  use_api_key: "KIE_AI_API_KEY_IMAGE_EDITING",
  baseCreditCost: 3,
  estimatedTimeSeconds: 120,
  costMultipliers: { nVariants: { "1": 1, "2": 1.16666, "4": 1.3333 } },
  apiEndpoint: "/api/v1/gpt4o-image/generate",
  payloadStructure: "flat",
  maxImages: 5,
  defaultOutputs: 1,

  // UI metadata
  isActive: true,
  logoUrl: "/logos/openai.png",
  modelFamily: "OpenAI",
  variantName: "ChatGPT 4o Image",
  displayOrderInFamily: 2,

  // Lock system
  isLocked: true,
  lockedFilePath: "src/lib/models/locked/image_editing/ChatGPT_4o_Image.ts",
} as const;

// FROZEN SCHEMA
export const SCHEMA = {
  type: "object",
  properties: {
    // Required/Primary parameters (shown in UI)
    prompt: {
      type: "string",
      description: "Text prompt that conveys the creative idea you want the 4o model to render",
      renderer: "prompt",
    },
    filesUrl: {
      type: "array",
      title: "Image",
      description:
        "Up to 5 image URLs to serve as reference or source material. Supported formats: .jfif, .pjpeg, .jpeg, .pjp, .jpg, .png, .webp",
      renderer: "image",
      items: { type: "string", format: "uri" },
      maxItems: 5,
    },
    size: {
      type: "string",
      title: "Aspect Ratio",
      description: "Aspect ratio of the generated image",
      default: "1:1",
      enum: ["1:1", "3:2", "2:3"],
    },
    nVariants: {
      type: "integer",
      title: "Number of Outputs",
      description: "How many image variations to produce. Each option has a different credit cost.",
      default: 1,
      enum: [1, 2, 4],
    },

    // Optional UI parameters
    maskUrl: {
      type: "string",
      showToUser: false,
      format: "uri",
      title: "Mask Image URL",
      description:
        "Mask image URL indicating areas to modify (black) versus preserve (white). Must match reference image dimensions. Ignored when multiple images supplied.",
      renderer: "image",
    },
    isEnhance: {
      type: "boolean",
      showToUser: false,
      title: "Enhance Prompt",
      description: "Enable prompt enhancement for more refined outputs in specialised scenarios (e.g., 3D renders)",
      default: false,
    },

    // Hidden/Advanced parameters (not shown in UI by default)
    enableFallback: {
      type: "boolean",
      showToUser: false,
      title: "Enable Fallback",
      description: "Activate automatic fallback to backup models if GPT-4o image generation is unavailable",
      default: false,
    },
    fallbackModel: {
      type: "string",
      showToUser: false,
      title: "Fallback Model",
      description: "Specify which backup model to use when the main model is unavailable",
      enum: ["GPT_IMAGE_1", "FLUX_MAX"],
      default: "FLUX_MAX",
    },
    uploadCn: {
      type: "boolean",
      title: "Upload via China Servers",
      description: "Choose the upload region. true routes uploads via China servers; false via non-China servers.",
      default: false,
      showToUser: false,
    },
  },
  required: ["prompt", "filesUrl", "size"],
};

// VALIDATION
export function validate(inputs: Record<string, any>): { valid: boolean; error?: string } {
  if (!inputs.size) {
    return { valid: false, error: "Size is required" };
  }
  if (!["1:1", "3:2", "2:3"].includes(inputs.size)) {
    return { valid: false, error: "Size must be one of: 1:1, 3:2, 2:3" };
  }

  // At least one of prompt or filesUrl must be provided
  const hasPrompt = inputs.prompt && inputs.prompt.length >= 1;
  const hasFiles = inputs.filesUrl && Array.isArray(inputs.filesUrl) && inputs.filesUrl.length > 0;

  if (!hasPrompt && !hasFiles) {
    return { valid: false, error: "At least one of prompt or image(s) must be provided" };
  }

  // Validate filesUrl if provided
  if (inputs.filesUrl && Array.isArray(inputs.filesUrl)) {
    if (inputs.filesUrl.length > 5) {
      return { valid: false, error: "Maximum 5 images allowed" };
    }
  }

  // Validate nVariants if provided
  if (inputs.nVariants !== undefined && ![1, 2, 4].includes(inputs.nVariants)) {
    return { valid: false, error: "nVariants must be 1, 2, or 4" };
  }

  // Validate fallbackModel if provided
  if (inputs.fallbackModel !== undefined && !["GPT_IMAGE_1", "FLUX_MAX"].includes(inputs.fallbackModel)) {
    return { valid: false, error: "fallbackModel must be GPT_IMAGE_1 or FLUX_MAX" };
  }

  return { valid: true };
}

// PAYLOAD PREPARATION
export function preparePayload(inputs: Record<string, any>): Record<string, any> {
  const payload: Record<string, any> = {
    size: inputs.size,
    nVariants: inputs.nVariants || 1,
  };

  // Add prompt if provided
  if (inputs.prompt) {
    payload.prompt = inputs.prompt;
  }

  // Add filesUrl if provided
  if (inputs.filesUrl && Array.isArray(inputs.filesUrl) && inputs.filesUrl.length > 0) {
    payload.filesUrl = inputs.filesUrl;
  }

  // Add optional parameters only if provided
  if (inputs.maskUrl) {
    payload.maskUrl = inputs.maskUrl;
  }

  if (inputs.isEnhance !== undefined) {
    payload.isEnhance = inputs.isEnhance;
  }

  if (inputs.enableFallback !== undefined) {
    payload.enableFallback = inputs.enableFallback;
  }

  if (inputs.fallbackModel) {
    payload.fallbackModel = inputs.fallbackModel;
  }

  if (inputs.uploadCn !== undefined) {
    payload.uploadCn = inputs.uploadCn;
  }

  // Note: callBackUrl is typically handled by the edge function, not passed from client

  return payload;
}

// COST CALCULATION
export function calculateCost(inputs: Record<string, any>): number {
  let cost = MODEL_CONFIG.baseCreditCost;
  const nVariants = inputs.nVariants || 1;
  const multiplier =
    MODEL_CONFIG.costMultipliers.nVariants[String(nVariants) as keyof typeof MODEL_CONFIG.costMultipliers.nVariants] ||
    1;
  cost *= multiplier;
  return Math.round(cost * 100) / 100;
}

// EXECUTION
export async function execute(params: ExecuteGenerationParams): Promise<string> {
  const { prompt, modelParameters, uploadedImages, userId, uploadImagesToStorage, startPolling } = params;
  const inputs: Record<string, any> = { ...modelParameters, prompt };

  // Upload images and get URLs if provided
  if (uploadedImages.length > 0) {
    inputs.filesUrl = await uploadImagesToStorage(userId);
  }

  // Validate inputs
  const validation = validate(inputs);
  if (!validation.valid) {
    throw new Error(validation.error);
  }

  // Calculate and reserve credits
  const cost = calculateCost(inputs);
  await reserveCredits(userId, cost);

  // Create generation record with pending status (edge function will process)
  const { data: gen, error } = await supabase
    .from("generations")
    .insert({
      user_id: userId,
      model_id: MODEL_CONFIG.modelId,
      model_record_id: MODEL_CONFIG.recordId,
      type: getGenerationType(MODEL_CONFIG.contentType),
      prompt,
      tokens_used: cost,
      status: GENERATION_STATUS.PENDING,
      settings: sanitizeForStorage(modelParameters),
    })
    .select()
    .single();

  if (error || !gen) {
    throw new Error(`Failed: ${error?.message}`);
  }

  // Call edge function to handle API call server-side
  // This keeps API keys secure and avoids CORS issues
  const { error: funcError } = await supabase.functions.invoke("generate-content", {
    body: {
      generationId: gen.id,
      model_config: MODEL_CONFIG,
      model_schema: SCHEMA,
      prompt,
      custom_parameters: preparePayload(inputs),
    },
  });

  if (funcError) {
    await supabase.from("generations").update({ status: GENERATION_STATUS.FAILED }).eq("id", gen.id);
    throw new Error(`Edge function failed: ${funcError.message}`);
  }

  startPolling(gen.id);
  return gen.id;
}
